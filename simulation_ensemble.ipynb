{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.BaseAutoEncoder import BaseSeq2Seq\n",
    "from src.dataload.tabular import tabularDataset\n",
    "from src.utils import ensemble_inference, inference\n",
    "from src.simulation_trainer import BaseTrainer, NewTrainer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _normalize_tabular(df: pd.DataFrame, label_name: str = \"label\"):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df.drop(label_name, axis=1))\n",
    "    y = df[label_name]\n",
    "    return X, y\n",
    "\n",
    "def simul_split_train_valid_test(df: pd.DataFrame, train_ratio: float = 0.7):\n",
    "    X, y = _normalize_tabular(df)\n",
    "    tmp = pd.DataFrame(X)\n",
    "    tmp[\"label\"] = y\n",
    "    normal = tmp.loc[tmp[\"label\"] == 0, :].reset_index(drop=True)\n",
    "    abnormal = tmp.loc[tmp[\"label\"] == 1, :].reset_index(drop=True)\n",
    "    X_train, X_val_test, y_train, y_val_test = train_test_split(\n",
    "        normal.drop(\"label\", axis=1),\n",
    "        normal[\"label\"],\n",
    "        train_size=train_ratio,\n",
    "        random_state=42,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_val_test, y_val_test, train_size=0.5, random_state=42, shuffle=False\n",
    "    )\n",
    "    X_test[\"label\"] = y_test\n",
    "    X_test = pd.concat([X_test, abnormal]).reset_index(drop=True)\n",
    "    return (\n",
    "        X_train.values,\n",
    "        X_val.values,\n",
    "        X_test.drop(\"label\", axis=1).values,\n",
    "        y_train.values,\n",
    "        y_val.values,\n",
    "        X_test[\"label\"].values,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=512, data='tabular', device='cuda:0', early_stop_round=50, hidden_size=[2], initial_epochs=[5, 20], n_epochs=1000, project='my_paper', sampling_ratio=[0.01, 0.1], sampling_term=[1, 5], train_ratio=0.7, trainer_name='BaseTrainer', window_size=60)\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "config = {\n",
    "    'trainer_name' : 'BaseTrainer',\n",
    "    'project' : 'my_paper',\n",
    "    'train_ratio': .7,\n",
    "    'batch_size': 512,\n",
    "    'n_epochs': 1000,\n",
    "    'early_stop_round': 50,\n",
    "    'hidden_size': [2],\n",
    "    'window_size': 60,\n",
    "    'data': 'tabular',\n",
    "    # 'sampling_term': [1, 5],\n",
    "    'sampling_term': [1, 5],\n",
    "    # 'initial_epochs': [10],\n",
    "    'initial_epochs': [5, 20],\n",
    "    'sampling_ratio': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# gpu\n",
    "gpu_id = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "if gpu_id == 0:\n",
    "    config['device'] = 'cuda:0'\n",
    "else:\n",
    "    config['device'] = 'cpu'\n",
    "\n",
    "config = Namespace(**config)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.deterministic = True\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 저장해야 할 것\n",
    "  - epoch=500일 때만\n",
    "    - top, down\n",
    "    - error\n",
    "  - 항상\n",
    "    - 모델 성능 result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시간이 너무 오래걸려서\n",
    "- big은 제외하고 일단 진행 -> 사이즈를 줄이던지 교수님들한테 피드백받고 추가하자\n",
    "- small에서 hidden_size=4의 경우는 데이터가 부족한 것 같다. 일단은 **h=4는 제외**하고 진행\n",
    "- **weight=0.5는 제외**하고 일단 진행\n",
    "- 500 epoch 부터는 sampling_term=1만 진행\n",
    "- simulation은 일단 500빼자 -> bench만 해보자\n",
    "- *BUGFIX* : sampling_term은 다 다시해야함\n",
    "### 일지 (1회당 30분 걸림, 일단 3회 진행)\n",
    "- `smallNormal.csv`\n",
    "    - epoch=1000 & early_stop=50: 3회\n",
    "    - epoch=500: 3회\n",
    "- `smallTestNoise_010_01.csv`\n",
    "    - epoch=1000 & early_stop=50: 3회\n",
    "    - epoch=500: 3회\n",
    "- `smallTestNoise_010_09.csv`\n",
    "    - epoch=1000 & early_stop=50: 3회\n",
    "- `smallTestNoise_010_05.csv`\n",
    "  - 제외\n",
    "- `smallTrainNoise_001_01.csv`\n",
    "  - epoch=1000 & early_stop=50: 3회\n",
    "- `smallTrainNoise_001_05.csv`\n",
    "  - 제외\n",
    "- `smallTrainNoise_001_09.csv`\n",
    "  - epoch=1000 & early_stop=50: 3회\n",
    "  - epoch=500 & init=20 & samTerm=[1,5,10]-> 1회 top down 분석\n",
    "- `smallTrainNoise_010_01.csv`\n",
    "  - epoch=1000 & early_stop=50: 3회\n",
    "  - epoch=500 & init=10 3회-> top down 분석\n",
    "- `smallTrainNoise_010_05.csv`\n",
    "  - 제외\n",
    "- `smallTrainNoise_010_09.csv`\n",
    "  - epoch=1000 & early_stop=50: 3회\n",
    "  - epoch=500 & init=10 1회-> top down 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble\n",
    "- 위의 config -> 총 8개 모델 이용해서 Ensemble\n",
    "\n",
    "```\n",
    "'sampling_term': [1, 5],\n",
    "'initial_epochs': [5, 20],\n",
    "'sampling_ratio': [0.01, 0.1]\n",
    "```\n",
    "\n",
    "- 실험진행 데이터\n",
    "  - `smallTrainNoise_010_09.csv`: 3 \n",
    "  - `smallTrainNoise_010_01.csv`: 3\n",
    "  - `smallTrainNoise_001_09.csv`: 3\n",
    "  - `smallTrainNoise_001_01.csv`: 3\n",
    "  - `smallTestNoise_010_09.csv`: 3\n",
    "  - `smallTestNoise_010_01.csv`: 3\n",
    "  - `smallNormal.csv`: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< 1번재 시작 >>\n",
      "-----NewTrainer starts-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-c9eb5218e970>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[\"label\"] = y_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped! in Epoch 97:\n",
      "train_loss=0.821, valid_loss=0.810\n",
      "New file generated!\n",
      "-----NewTrainer starts-----\n",
      "Early Stopped! in Epoch 281:\n",
      "train_loss=0.797, valid_loss=0.740\n",
      "-----NewTrainer starts-----\n",
      "Early Stopped! in Epoch 194:\n",
      "train_loss=0.796, valid_loss=0.756\n",
      "-----NewTrainer starts-----\n",
      "Early Stopped! in Epoch 85:\n",
      "train_loss=0.813, valid_loss=0.818\n",
      "-----NewTrainer starts-----\n",
      "Early Stopped! in Epoch 488:\n",
      "train_loss=0.730, valid_loss=0.733\n",
      "-----NewTrainer starts-----\n",
      "Early Stopped! in Epoch 565:\n",
      "train_loss=0.762, valid_loss=0.783\n",
      "-----NewTrainer starts-----\n",
      "Early Stopped! in Epoch 159:\n",
      "train_loss=0.766, valid_loss=0.802\n",
      "-----NewTrainer starts-----\n",
      "Early Stopped! in Epoch 108:\n",
      "train_loss=0.771, valid_loss=0.810\n"
     ]
    }
   ],
   "source": [
    "data_list = ['smallTrainNoise_010_09.csv']\n",
    "\n",
    "n_time = 1\n",
    "PATH = './run_result_sim_nodrop/'\n",
    "# save_idx = '_2'\n",
    "\n",
    "for d in data_list:\n",
    "    data = pd.read_csv('./sim_data/' + d)\n",
    "    config.data_name = d.split('.')[0]\n",
    "        # 500epoch이고 train에 noise가 있는 경우에만 error, top, down 확인\n",
    "    if (config.n_epochs == 500) and ('Train' in config.data_name):\n",
    "        is_debug = True\n",
    "    else:\n",
    "        is_debug = False\n",
    "        \n",
    "    for i in range(n_time):\n",
    "\n",
    "        print(f'<< {i+1}번재 시작 >>')\n",
    "        (\n",
    "            train_x,\n",
    "            valid_x,\n",
    "            test_x,\n",
    "            train_y,\n",
    "            valid_y,\n",
    "            test_y,\n",
    "        ) = simul_split_train_valid_test(data, config.train_ratio)\n",
    "        \n",
    "        # resize 'window_size' = 'col_len'\n",
    "        config.window_size = train_x.shape[1]\n",
    "\n",
    "        train_dataset = tabularDataset(train_x, train_y)\n",
    "        valid_dataset = tabularDataset(valid_x, valid_y)\n",
    "        test_dataset = tabularDataset(test_x, test_y)\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, shuffle=False, batch_size=config.batch_size\n",
    "        )\n",
    "        valid_dataloader = DataLoader(\n",
    "            valid_dataset, shuffle=False, batch_size=config.batch_size\n",
    "        )\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset, shuffle=False, batch_size=config.batch_size\n",
    "        )\n",
    "\n",
    "        total_x = np.concatenate([train_x, valid_x, test_x])\n",
    "        total_y = np.concatenate([train_y, valid_y, test_y])\n",
    "        IR = round((len(total_y) - np.sum(total_y)) / np.sum(total_y), 4)\n",
    "        \n",
    "        # for inference\n",
    "        total_dataset = tabularDataset(total_x, total_y)\n",
    "        total_dataloader = DataLoader(\n",
    "            total_dataset, shuffle=False, batch_size=config.batch_size\n",
    "        )\n",
    "\n",
    "        # if is_debug is False:\n",
    "        #     for hidden_size in config.hidden_size:\n",
    "        #         print(f\"-----BaseTrainer starts with hidden_size={hidden_size}-----\")\n",
    "        #         config.trainer_name = \"BaseTrainer\"\n",
    "\n",
    "        #         model = BaseSeq2Seq(\n",
    "        #             input_size=config.window_size,\n",
    "        #             hidden_size=hidden_size,\n",
    "        #             output_size=config.window_size,\n",
    "        #             dropout_p=0.2,\n",
    "        #         ).to(config.device)\n",
    "\n",
    "        #         optimizer = optim.Adam(model.parameters())\n",
    "        #         criterion = nn.MSELoss()\n",
    "\n",
    "        #         # train\n",
    "        #         trainer = BaseTrainer(model=model, optimizer=optimizer, crit=criterion)\n",
    "\n",
    "        #         train_loss, val_loss, return_epoch, best_model = trainer.train(\n",
    "        #             train_loader=train_dataloader,\n",
    "        #             val_loader=valid_dataloader,\n",
    "        #             config=config,\n",
    "        #             use_wandb=False,\n",
    "        #         )\n",
    "\n",
    "        #         best_model.to(\"cpu\")                        \n",
    "        #         sampling_term = 0\n",
    "        #         sampling_ratio = 0\n",
    "        #         initial_epoch = 0\n",
    "\n",
    "        #         df, tst_ano_score = ensemble_inference(\n",
    "        #             config,\n",
    "        #             total_dataloader,\n",
    "        #             best_model,\n",
    "        #             train_x,\n",
    "        #             valid_x,\n",
    "        #             total_x,\n",
    "        #             total_y,\n",
    "        #             return_epoch,\n",
    "        #             hidden_size,\n",
    "        #             train_loss,\n",
    "        #             val_loss,\n",
    "        #             IR,\n",
    "        #             sampling_term,\n",
    "        #             sampling_ratio,\n",
    "        #             initial_epoch,\n",
    "        #             PATH\n",
    "        #         )\n",
    "        #         df.to_csv(PATH + \"result_\" + config.data_name + \".csv\", index=False)\n",
    "                \n",
    "        #         #hp = '_hs' + str(hidden_size) + '_st' + str(sampling_term) + '_sr' + str(sampling_ratio) + '_ie' + str(initial_epoch)\n",
    "        #         with open('./ensemble_sim_base_1/' + config.data_name + '.pickle', 'wb') as f:\n",
    "        #             pickle.dump(tst_ano_score, f, pickle.HIGHEST_PROTOCOL)\n",
    "        #         torch.cuda.empty_cache()\n",
    "            \n",
    "        for hidden_size in config.hidden_size:\n",
    "            for sampling_ratio in config.sampling_ratio:\n",
    "                for initial_epoch in config.initial_epochs: \n",
    "                    for sampling_term in config.sampling_term:\n",
    "                        print(\n",
    "                            f\"-----NewTrainer starts-----\"\n",
    "                        )\n",
    "                        config.trainer_name = \"NewTrainer\"\n",
    "\n",
    "                        model = BaseSeq2Seq(\n",
    "                            input_size=config.window_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            output_size=config.window_size,\n",
    "                            dropout_p=0.2,\n",
    "                        ).to(config.device)\n",
    "\n",
    "                        optimizer = optim.Adam(model.parameters())\n",
    "                        criterion = nn.MSELoss()\n",
    "\n",
    "                        # train\n",
    "                        trainer = NewTrainer(model=model, optimizer=optimizer, crit=criterion)\n",
    "                        \n",
    "                        train_loss, val_loss, return_epoch, best_model, errors, tops, downs = trainer.train(\n",
    "                            train_x=train_x,\n",
    "                            train_y=train_y,\n",
    "                            train_loader=train_dataloader,\n",
    "                            val_loader=valid_dataloader,\n",
    "                            sampling_term=sampling_term,\n",
    "                            initial_epoch=initial_epoch,\n",
    "                            sampling_ratio=sampling_ratio,\n",
    "                            config=config,\n",
    "                            use_wandb=False,\n",
    "                            is_debug=is_debug\n",
    "                        )\n",
    "                        if is_debug:\n",
    "                            hp = '_h' + str(hidden_size) + '_st' + str(sampling_term) + '_sr' + str(sampling_ratio) + '_ie' + str(initial_epoch)\n",
    "                            with open('./run_result_sim_error/newError_'+ config.data_name + hp + save_idx + '.pickle', 'wb') as f:\n",
    "                                pickle.dump(errors, f, pickle.HIGHEST_PROTOCOL)\n",
    "                            with open('./run_result_sim_top/newTop_'+ config.data_name + hp + save_idx + '.pickle', 'wb') as f:\n",
    "                                pickle.dump(tops, f, pickle.HIGHEST_PROTOCOL)\n",
    "                            with open('./run_result_sim_down/newDown_'+ config.data_name + hp + save_idx + '.pickle', 'wb') as f:\n",
    "                                pickle.dump(downs, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "                        best_model.to(\"cpu\")                                \n",
    "\n",
    "                        df, tst_ano_score = ensemble_inference(\n",
    "                            config,\n",
    "                            total_dataloader,\n",
    "                            best_model,\n",
    "                            train_x,\n",
    "                            valid_x,\n",
    "                            total_x,\n",
    "                            total_y,\n",
    "                            return_epoch,\n",
    "                            hidden_size,\n",
    "                            train_loss,\n",
    "                            val_loss,\n",
    "                            IR,\n",
    "                            sampling_term,\n",
    "                            sampling_ratio,\n",
    "                            initial_epoch,\n",
    "                            PATH\n",
    "                        )\n",
    "                        df.to_csv(PATH + \"result_\" + config.data_name + \".csv\", index=False)\n",
    "                        \n",
    "                        hp = '_hs' + str(hidden_size) + '_st' + str(sampling_term) + '_sr' + str(sampling_ratio) + '_ie' + str(initial_epoch)\n",
    "                        with open('./ensemble_sim_nodrop_1/' + config.data_name + hp + '.pickle', 'wb') as f:\n",
    "                            pickle.dump(tst_ano_score, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "                        torch.cuda.empty_cache()\n",
    "                                                \n",
    "frequency = 800\n",
    "duration = 2000\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pr_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainer_name</th>\n",
       "      <th>sampling_term</th>\n",
       "      <th>sampling_ratio</th>\n",
       "      <th>initial_epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaseTrainer</th>\n",
       "      <th>0</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0</th>\n",
       "      <td>0.702217</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.638217</td>\n",
       "      <td>0.016841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">NewTrainer</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.01</th>\n",
       "      <th>5</th>\n",
       "      <td>0.699967</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.634067</td>\n",
       "      <td>0.016909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.697700</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>0.628667</td>\n",
       "      <td>0.026074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.705667</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.643167</td>\n",
       "      <td>0.007978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.10</th>\n",
       "      <th>5</th>\n",
       "      <td>0.698014</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.633457</td>\n",
       "      <td>0.012629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.699975</td>\n",
       "      <td>0.016628</td>\n",
       "      <td>0.634725</td>\n",
       "      <td>0.022941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.692275</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>0.623475</td>\n",
       "      <td>0.016610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.01</th>\n",
       "      <th>5</th>\n",
       "      <td>0.696933</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.008292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.701067</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>0.636100</td>\n",
       "      <td>0.020236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.10</th>\n",
       "      <th>5</th>\n",
       "      <td>0.685867</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.615333</td>\n",
       "      <td>0.014739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.699533</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.631367</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          roc_auc            \\\n",
       "                                                             mean       std   \n",
       "trainer_name sampling_term sampling_ratio initial_epoch                       \n",
       "BaseTrainer  0             0.00           0              0.702217  0.012748   \n",
       "NewTrainer   1             0.01           5              0.699967  0.012785   \n",
       "                                          10             0.697700  0.018557   \n",
       "                                          20             0.705667  0.006673   \n",
       "                           0.10           5              0.698014  0.008948   \n",
       "                                          10             0.699975  0.016628   \n",
       "                                          20             0.692275  0.011288   \n",
       "             5             0.01           5              0.696933  0.009504   \n",
       "                                          20             0.701067  0.013002   \n",
       "                           0.10           5              0.685867  0.009851   \n",
       "                                          20             0.699533  0.010920   \n",
       "\n",
       "                                                           pr_auc            \n",
       "                                                             mean       std  \n",
       "trainer_name sampling_term sampling_ratio initial_epoch                      \n",
       "BaseTrainer  0             0.00           0              0.638217  0.016841  \n",
       "NewTrainer   1             0.01           5              0.634067  0.016909  \n",
       "                                          10             0.628667  0.026074  \n",
       "                                          20             0.643167  0.007978  \n",
       "                           0.10           5              0.633457  0.012629  \n",
       "                                          10             0.634725  0.022941  \n",
       "                                          20             0.623475  0.016610  \n",
       "             5             0.01           5              0.633867  0.008292  \n",
       "                                          20             0.636100  0.020236  \n",
       "                           0.10           5              0.615333  0.014739  \n",
       "                                          20             0.631367  0.016500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./run_result_sim/result_' + config.data_name + '.csv')\n",
    "cols = ['trainer_name', 'sampling_term','sampling_ratio','initial_epoch']\n",
    "df.groupby(cols)[['roc_auc','pr_auc']].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.755279</td>\n",
       "      <td>0.74738</td>\n",
       "      <td>0.706091</td>\n",
       "      <td>0.798706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_auc</th>\n",
       "      <td>0.708022</td>\n",
       "      <td>0.696569</td>\n",
       "      <td>0.637348</td>\n",
       "      <td>0.755849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean    median       max       min\n",
       "roc_auc  0.755279   0.74738  0.706091  0.798706\n",
       "pr_auc   0.708022  0.696569  0.637348  0.755849"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "anomaly_score = np.zeros((len(test_y), 8))\n",
    "\n",
    "result_df = pd.DataFrame(columns=['mean','median','max','min'], index=['roc_auc','pr_auc'])\n",
    "\n",
    "PATH = './ensemble_sim_base_1/'\n",
    "idx = 0\n",
    "for data_name in os.listdir(PATH):\n",
    "    if config.data_name in data_name:\n",
    "        with open(PATH + data_name, 'rb') as f:\n",
    "            tmp = pickle.load(f)\n",
    "            anomaly_score[:, idx] = tmp\n",
    "            idx += 1\n",
    "\n",
    "tst_ano_scr_med = np.median(anomaly_score, axis=1)\n",
    "tst_ano_scr_mean = np.mean(anomaly_score, axis=1)\n",
    "tst_ano_scr_max = np.max(anomaly_score, axis=1)\n",
    "tst_ano_scr_min = np.min(anomaly_score, axis=1)\n",
    "\n",
    "idx = 0\n",
    "for tst_ano_scr in [tst_ano_scr_mean, tst_ano_scr_med, tst_ano_scr_max, tst_ano_scr_min]:\n",
    "    roc_auc = roc_auc_score(test_y, tst_ano_scr)\n",
    "    _precision, _recall, _ = precision_recall_curve(test_y, tst_ano_scr)\n",
    "    pr_auc = auc(_recall, _precision)\n",
    "    result_df.iloc[0, idx] = roc_auc\n",
    "    result_df.iloc[1, idx] = pr_auc\n",
    "    idx += 1\n",
    "\n",
    "result_df\n",
    "# if config.data == \"tabular\":\n",
    "#     tst_y_true = total_y[-len(tst_ano_scr):]\n",
    "# else:\n",
    "    # tst_y_true = total_y[tst_start_idx : len(window_anomaly_score_result)] # 여기 time_series 계산\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4829241e38f97ce9549fd9dd142f37034ca40da852944784ae6a4626739d5593"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
