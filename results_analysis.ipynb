{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = './run_results_tabular/'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.csv')]\n",
    "\n",
    "import os\n",
    "\n",
    "path = './run_results_time/'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(return_epoch, file_list_py):\n",
    "    df = pd.read_csv(path + file_list_py[0])\n",
    "    total_df = pd.DataFrame(df.loc[(df['early_stop_round']==1000) & (df['return_epoch']==return_epoch),:].groupby(['trainer_name','hidden_size','sampling_term'])['roc_auc'].max()).rename(columns={'roc_auc': file_list_py[0]})\n",
    "    for i in range(1, len(file_list_py)):\n",
    "        df = pd.read_csv(path + file_list_py[i])\n",
    "        tmp = pd.DataFrame(df.loc[(df['early_stop_round']==1000) & (df['return_epoch']==return_epoch),:].groupby(['trainer_name','hidden_size','sampling_term'])['roc_auc'].max()).rename(columns={'roc_auc': file_list_py[i]})\n",
    "        total_df = pd.concat([total_df, tmp], axis=1)\n",
    "    total_df = total_df.T\n",
    "\n",
    "    total_df.loc[len(file_list_py)] = np.mean(total_df, axis=0)\n",
    "    total_df = total_df.rename(index={len(file_list_py):'mean'})\n",
    "\n",
    "    only_hidden_size = total_df[('BaseTrainer')]\n",
    "    for i in [2, 4, 8]:\n",
    "        only_hidden_size[(i,'max')] = np.max(total_df[('NewTrainer', i)], axis=1)\n",
    "        only_hidden_size.loc['mean',:] = np.mean(only_hidden_size.iloc[:-1, :], axis=0)\n",
    "        \n",
    "    t_test_df = pd.DataFrame(index=only_hidden_size.columns, columns=only_hidden_size.columns)\n",
    "    for col1 in only_hidden_size.columns:\n",
    "        for col2 in only_hidden_size.columns:\n",
    "            result = scipy.stats.ttest_ind(only_hidden_size[col1], only_hidden_size[col2], equal_var=False)\n",
    "            if result.pvalue <= 0.05:\n",
    "                t_test_df.loc[col1, col2] = 1\n",
    "            else:\n",
    "                t_test_df.loc[col1, col2] = 0\n",
    "    return total_df, only_hidden_size, t_test_df\n",
    "\n",
    "def roc_auc_early_stop(file_list_py):\n",
    "    df = pd.read_csv(path + file_list_py[0])\n",
    "    total_df = pd.DataFrame(df.loc[(df['early_stop_round']!=1000),:].groupby(['trainer_name','hidden_size','sampling_term'])['roc_auc'].max()).rename(columns={'roc_auc': file_list_py[0]})\n",
    "    for i in range(1, len(file_list_py)):\n",
    "        df = pd.read_csv(path + file_list_py[i])\n",
    "        tmp = pd.DataFrame(df.loc[(df['early_stop_round']!=1000),:].groupby(['trainer_name','hidden_size','sampling_term'])['roc_auc'].max()).rename(columns={'roc_auc': file_list_py[i]})\n",
    "        total_df = pd.concat([total_df, tmp], axis=1)\n",
    "    total_df = total_df.T\n",
    "\n",
    "    total_df.loc[len(file_list_py)] = np.mean(total_df, axis=0)\n",
    "    total_df = total_df.rename(index={len(file_list_py):'mean'})\n",
    "\n",
    "    only_hidden_size = total_df[('BaseTrainer')]\n",
    "    for i in [2, 4, 8]:\n",
    "        only_hidden_size[(i,'max')] = np.max(total_df[('NewTrainer', i)], axis=1)\n",
    "        only_hidden_size.loc['mean',:] = np.mean(only_hidden_size.iloc[:-1, :], axis=0)\n",
    "        \n",
    "    t_test_df = pd.DataFrame(index=only_hidden_size.columns, columns=only_hidden_size.columns)\n",
    "    for col1 in only_hidden_size.columns:\n",
    "        for col2 in only_hidden_size.columns:\n",
    "            result = scipy.stats.ttest_ind(only_hidden_size[col1], only_hidden_size[col2], equal_var=False)\n",
    "            if result.pvalue <= 0.05:\n",
    "                t_test_df.loc[col1, col2] = 1\n",
    "            else:\n",
    "                t_test_df.loc[col1, col2] = 0\n",
    "    return total_df, only_hidden_size, t_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(return_epoch, file_list_py):\n",
    "    df = pd.read_csv(path + file_list_py[0])\n",
    "    total_df = pd.DataFrame(df.loc[(df['early_stop_round']==1000) & (df['return_epoch']==return_epoch),:].groupby(['trainer_name','hidden_size','sampling_term'])['pr_auc'].max()).rename(columns={'pr_auc': file_list_py[0]})\n",
    "    for i in range(1, len(file_list_py)):\n",
    "        df = pd.read_csv(path + file_list_py[i])\n",
    "        tmp = pd.DataFrame(df.loc[(df['early_stop_round']==1000) & (df['return_epoch']==return_epoch),:].groupby(['trainer_name','hidden_size','sampling_term'])['pr_auc'].max()).rename(columns={'pr_auc': file_list_py[i]})\n",
    "        total_df = pd.concat([total_df, tmp], axis=1)\n",
    "    total_df = total_df.T\n",
    "\n",
    "    total_df.loc[len(file_list_py),:] = np.mean(total_df, axis=0)\n",
    "    print(len(total_df))\n",
    "    total_df = total_df.rename(index={len(file_list_py):'mean'})\n",
    "\n",
    "    only_hidden_size = total_df[('BaseTrainer')]\n",
    "    for i in [2, 4, 8]:\n",
    "        only_hidden_size[(i,'max')] = np.max(total_df[('NewTrainer', i)], axis=1)\n",
    "        only_hidden_size.loc['mean',:] = np.mean(only_hidden_size.iloc[:-1, :], axis=0)\n",
    "        \n",
    "    t_test_df = pd.DataFrame(index=only_hidden_size.columns, columns=only_hidden_size.columns)\n",
    "    for col1 in only_hidden_size.columns:\n",
    "        for col2 in only_hidden_size.columns:\n",
    "            result = scipy.stats.ttest_ind(only_hidden_size[col1], only_hidden_size[col2], equal_var=False)\n",
    "            if result.pvalue <= 0.05:\n",
    "                t_test_df.loc[col1, col2] = 1\n",
    "            else:\n",
    "                t_test_df.loc[col1, col2] = 0\n",
    "    return total_df, only_hidden_size, t_test_df\n",
    "\n",
    "def pr_auc_early(return_epoch, file_list_py):\n",
    "    df = pd.read_csv(path + file_list_py[0])\n",
    "    total_df = pd.DataFrame(df.loc[(df['early_stop_round']!=1000),:].groupby(['trainer_name','hidden_size','sampling_term'])['pr_auc'].max()).rename(columns={'pr_auc': file_list_py[0]})\n",
    "    for i in range(1, len(file_list_py)):\n",
    "        df = pd.read_csv(path + file_list_py[i])\n",
    "        tmp = pd.DataFrame(df.loc[(df['early_stop_round']==1000),:].groupby(['trainer_name','hidden_size','sampling_term'])['pr_auc'].max()).rename(columns={'pr_auc': file_list_py[i]})\n",
    "        total_df = pd.concat([total_df, tmp], axis=1)\n",
    "    total_df = total_df.T\n",
    "\n",
    "    total_df.loc[len(file_list_py),:] = np.mean(total_df, axis=0)\n",
    "    print(len(total_df))\n",
    "    total_df = total_df.rename(index={len(file_list_py):'mean'})\n",
    "\n",
    "    only_hidden_size = total_df[('BaseTrainer')]\n",
    "    for i in [2, 4, 8]:\n",
    "        only_hidden_size[(i,'max')] = np.max(total_df[('NewTrainer', i)], axis=1)\n",
    "        only_hidden_size.loc['mean',:] = np.mean(only_hidden_size.iloc[:-1, :], axis=0)\n",
    "        \n",
    "    t_test_df = pd.DataFrame(index=only_hidden_size.columns, columns=only_hidden_size.columns)\n",
    "    for col1 in only_hidden_size.columns:\n",
    "        for col2 in only_hidden_size.columns:\n",
    "            result = scipy.stats.ttest_ind(only_hidden_size[col1], only_hidden_size[col2], equal_var=False)\n",
    "            if result.pvalue <= 0.05:\n",
    "                t_test_df.loc[col1, col2] = 1\n",
    "            else:\n",
    "                t_test_df.loc[col1, col2] = 0\n",
    "    return total_df, only_hidden_size, t_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anomaly score EDA\n",
    "- train, val, true anomaly score확인\n",
    "- 전반적으로 anomaly score가 높아지는지, 그에 비해 true anomaly score가 더 높아진다면..? 성공적\n",
    "  - threshold기반으로 결국 결정을 하는데 적절한 threshold를 더 잘 찾을 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# early stop epoch 확인\n",
    "- new방법이 더 빨리 early stop하면? 개이득"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4829241e38f97ce9549fd9dd142f37034ca40da852944784ae6a4626739d5593"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
